### 一、项目简介

整个项目使用了go-zero开发的微服务，基本包含了go-zero以及相关go-zero作者开发的一些中间件，所用到的技术栈基本是go-zero项目组的自研组件，基本是go-zero全家桶了

项目目录结构如下：


- app：所有业务代码包含api、rpc以及mq（消息队列、延迟队列、定时任务）

- common：通用组件 error、middleware、interceptor、tool、ctxdata等

- data：该项目依赖所有中间件(mysql、es、redis、grafana等)产生的数据，此目录下的所有内容应该在git忽略文件中，不需要提交。

- deploy：

    - filebeat: docker部署filebeat配置
    - go-stash：go-stash配置
    - nginx: nginx网关配置
    - prometheus ： prometheus配置
    - script：
        - gencode：生成api、rpc，以及创建kafka语句，复制粘贴使用
        - mysql：生成model的sh工具
    - goctl: 该项目goctl的template，goctl生成自定义代码模版，tempalte用法可参考go-zero文档，复制到家目录下.goctl即可，
      该项目用到goctl版本是v1.2.3

- doc : 该项目系列文档




### 二、用到技术栈

- go-zero
- nginx网关
- filebeat
- kafka
- go-stash
- elasticsearch
- kibana
- prometheus
- grafana
- jager
- go-queue
- asynq
- dtm
- docker
- docker-compose
- mysql
- redis



### 三、项目架构图

![gozerolooklook](./images/1/gozerolooklook.png)



### 四、项目环境搭建

本项目采用air热加载功即时修改代码及时生效，并且不需要每次都要重启，改了代码自动就在容器中重新加载了，本地不需要启动服务，本地安装的sdk就是写代码自动提示使用的，实际运行是以来容器中cosmtrek/air的golang环境。所以使用goland、vscode都一样



#### 1、clone代码&更新依赖

```shell
$ git clone git@github.com:Mikaelemmmm/go-zero-looklook.git
$ go mod tidy
```

#### 2、启动项目

```shell
$ docker-compose up -d
```

项目所依赖的服务（比如 prometheus、es、mysql等） 以及 项目本身的服务都定义在docker-compose中，直接docker-compose即可启动所有项目服务以及依赖的服务，如果后续家添加业务服务，直接docker-compose create【srv-name】 , docker-compose start 【srv-name】即可

#### 3、创建准备工作

1、日志收集到es（filebeat收集日志->kafka -> go-stash消费kafka日志->输出到es中,kibana查看es数据）

所以要提前在kafka中创建日志的topic

进入kafka容器

```shell
$ docker exec -it kafka /bin/sh
```

创建log的topic

```shell
$ cd /opt/kafka/bin
$ ./kafka-topics.sh --create --zookeeper zookeeper:2181 --replication-factor 1 -partitions 1 --topic looklook-log
```



2、创建数据库导入mysql数据

创建数据库looklook_order && 导入deploy/sql/looklook_order.sql数据

创建数据库looklook_payment && 导入deploy/sql/looklook_payment.sql数据

创建数据库looklook_travel && 导入deploy/sql/looklook_travel.sql数据

创建数据库looklook_usercenter && 导入looklook_usercenter.sql数据



3、查看业务的中间件配置，在docker-compose中写的 or 配置在deploy文件夹下



4、由于涉及到中间件镜像比较大，如果是第一次执行docker-compose up ,可能会有没有启动成功的，等所有服务都启动镜像下载完成之后

docker-compose down一次，然后在docker-compose up ，在依次检查一下所有服务跟第三方服务的启动情况

```shell
$ docker-compose ps
$ docker logs -f xxxxxx
```

【注】如果看日志哪个服务没有启动，或者其依赖的服务没有启动成功，直接docker restart xxx那个服务就可以了



5、访问kibana http://127.0.0.1:5601/ ， 创建日志索引

点击左上角菜单，找到Analytics - > 点击discover -> Create index pattern->输入looklook-*  -> Next Step ->选择@timestamp->Create index pattern

点击左上角菜单，找到Analytics->点击discover ，日志都显示了 （如果不显示，就去排查filebeat、go-stash）



#### 4、镜像介绍

所有服务启动成功，应该是如下这些，自行对比

![image-20220117221816047](/Users/seven/Desktop/gozerolooklook/images/1/image-20220117221816047.png)

- nginx : 网关 （nginx->api->rpc）
- cosmtrek/air : 我们业务代码开发以来的环境镜像，这个景象是air+golang，实际上我们启我们自己的业务服务后，我们的业务服务是运行在此镜像中的
- wurstmeister/kafka ： 业务使用的kafka
- wurstmeister/zookeeper ： kafka以来的zookeeper
- redis：业务使用的redis
- mysql: 业务使用的数据库
- prom/prometheus：监控业务
- grafana/grafana ：prometheus的ui很难看，用来显示prometheus收集来的数据
- elastic/filebeat ： 收集日志到kafka
- go-stash : 消费kafka中日志，脱敏、过滤然后输出到es
- docker.elastic.co/elasticsearch/elasticsearch ： 存储收集的日志
- docker.elastic.co/kibana/kibana ： 显示elasticsearch
- jaegertracing/jaeger-query 、jaegertracing/jaeger-collector、jaegertracing/jaeger-agent：链路追踪
- go-stash : filebeat收集日志到kafka后，go-stash去消费kafka进行数据脱敏、过滤日志中内容，最后输出到es中



#### 5、导入mysql数据

在项目目录的data/sql下，将本项目所用到的数据库以及表导入到mysql中，mysql也是使用docker-compose安装的，端口是33069,在用ui工具连接mysql时候注意一下，连接后直接倒入数据即可



#### 6、访问项目

由于我们使用nginx做的网关，也是配置在docker-compose中，nignx对外暴露端口是8888，所以我们通过8888端口访问

```shell
$ curl  -X POST "http://127.0.0.1:8888/usercenter/v1/user/register" -H "Content-Type: application/json" -d "{\"mobile\":\"18888888888\",\"password\":\"123456\"}" 

返回:
{"code":200,"msg":"OK","data":{"accessToken":"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2NzM5NjY0MjUsImlhdCI6MTY0MjQzMDQyNSwiand0VXNlcklkIjo1fQ.E5-yMF0OvNpBcfr0WyDxuTq1SRWGC3yZb9_Xpxtzlyw","accessExpire":1673966425,"refreshAfter":1658198425}}
```



#### 7、访问依赖服务

jaeger:

![image-20220117181505739](./images/1/image-20220117181505739.png)


kibana  : http://127.0.0.1:5601/

![image-20220117180955110](./images/1/kibana-log-img.png)

Elastic search: http://127.0.0.1:9200/

![image-20220117181055811](./images/1/image-20220117181055811.png)


Prometheus: http://127.0.0.1:9090/

![image-20220117181236322](./images/1/image-20220117181236322.png)

Grafana: http://127.0.0.1:3001/

![image-20220117181325845](./images/1/image-20220117181325845.png)




#### 8、项目开发建议

- app下放所有业务服务代码

- common放所有服务的公共基础库

- data目录实际开发中可以在git中忽略

- 生成api、rpc代码：

一般我们在生成api，rpc代码时候手动去敲goctl的命令比较长，也记不住，所以我们直接去deploy/script/gencode/gen.sh中复制代码即可。比如我在usercenter服务中新增加了一个业务，修改密码，写完api文件之后，进入到usercenter/cmd目录下，直接复制deploy/script/gencode/gen.sh中的生成api命令运行即可

```shell
$ goctl api go -api ./api/desc/*.api -dir ./api -style=goZero
```

生成rpc也一样，在写完proto文件后，直接粘复制deploy/script/gencode/gen.sh中的生成rpc命令运行即可

```shell
$ goctl rpc proto -src rpc/pb/*.proto -dir ./rpc -style=goZero
$ sed -i 's/,omitempty//g'  ./rpc/pb/*.pb.go
```

【注】建议在生成rpc文件时候，在多执行一次下面那个命令，把protobuf生成的omitempty给删除掉，不然字段为nil就不返回了

- 生成kafka代码：

  因为本项目使用了go-queue的kq做消息队列，kq又依赖的kafka，实际就是使用了kafka做消息队列，但是kq默认是需要我们提前把topic建好的，不许默认自动生成，所以命令也准备好了，直接复制deploy/script/gencode/gen.sh中的创建kafka的topic代码即可

  ```shell
   kafka-topics.sh --create --zookeeper zookeeper:2181 --replication-factor 1 -partitions 1 --topic {topic}
  ```



- 生成model代码，直接运行deploy/script/mysql/genModel.sh  参数

- api项目中的.api文件我们做了拆分，统一放到每个api的desc文件夹下，因为如果所有内容都写在api中可能不便于查看，所以做了拆分，把所有方法写到一个api中，其他的实体以及req、rep统一放到一个文件夹单独定义比较清晰

- 生成model、错误处理时候使用了template重新定义，该项目用到的自定义的goctl的模版在项目data/goctl下



#### 9、后续

由于项目中由于涉及到的技术栈稍微有点多，将逐步分章节一点点添加























